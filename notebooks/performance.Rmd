---
title: "performance"
author: "Jin"
date: "2021年5月14日"
output: html_document
---

- Set working directory
```{r setup}
your.wd <- "/home/jinyunfan/Documents/bioinfo/exRNA/ez-prediction"
knitr::opts_knit$set(root.dir = your.wd)
```

## Prepare training and testing data
```{R}
sample.info <- read.table("metadata/dataset.split.txt", header = T, sep ="\t",row.names=1,stringsAsFactors = F,check.names = F)
exp.mat <- read.table("output/processed/log.cpm.scaled.txt", header = T, sep ="\t",row.names=1,stringsAsFactors = F,check.names = F)
exp.mat <- as.matrix(exp.mat)
train.ids <- rownames(sample.info)[sample.info$dataset=="train"]
test.ids <- rownames(sample.info)[sample.info$dataset=="test"]
selected.features <- read.table("output/features/de.train.txt", header = T, sep ="\t",row.names=1,stringsAsFactors = F,check.names = F)

feature.ids <- rownames(selected.features)
n.features <- length(feature.ids)
feature.ids <- feature.ids[1:50]
```


```{R}
train.exp.mat <- as.matrix(t(exp.mat[feature.ids,train.ids]))
test.exp.mat <- as.matrix(t(exp.mat[feature.ids,test.ids]))

# If you set stringsAsFactors = F in read.table function, the response variable in `sample.info` is not of factor type

train.labels <- sample.info[train.ids,"tissue.types"]
train.labels <- factor(train.labels,level=c("normal","tumor"))

test.labels <- sample.info[test.ids,"tissue.types"]
test.labels <- factor(test.labels,level=c("normal","tumor"))
```


```{R}
library(glmnet)
library(pROC)
```

- As we expected, the model performance is perfect, as tumor and tumor adjancent tissue are highly distinct
- May serve as positive control when you want to do some sanity check on other methods, as this dataset should always give perfect results


## Logistic regression
- Logistic regression for cross validation and performance evaluation
- Cross validation: tune the regularize factor lambda 
- `glmnet`
```{R}
# Cross validation
cv.lr.result <- cv.glmnet(train.exp.mat,train.labels,family="binomial",nfolds = length(train.labels))
cv.lr.result$lambda.min
# Plot relation between loss and hyper-parameter lambda 
#plot(cv.lr.result$lambda,cv.lr.result$cvm)
pred.proba <- predict.glmnet(cv.lr.result$glmnet.fit,newx=test.exp.mat, type="response", s =cv.lr.result$lambda.min)
```
- Evaluate performance
  - Calculate AUROC with `ci.auc`
  - Calculate best `recall` and `precision` with `ci.coords`
  
```{R}
roc.curve <- roc(test.labels,as.numeric(pred.proba))
ci.auc(roc.curve,x="best",conf.level = 0.95)
plot(1-roc.curve$specificities,roc.curve$sensitivities,type="l")
# best.method=c("youden", "closest.topleft")
# youden by default. 
ci.coords(roc.curve,x="best",conf.level = 0.95,ret = c("recall","precision"),best.method="youden")
```


- We can do exactly same things with SVM, GBDT, and random forest

## SVM
- SVM, use package `e1071`
- Default parameters usually works well
- If perform cross validation, tune hyper-parameter `gamma` and `cost`
```{R}
library(e1071)
# search space of gamma: 2^(-1:1)/50, 1/(data dimension) by default 
# search space of cost: 2^(-1:1), 1 by default
gamma <- 2^(-2:2)/50
cost <- 2^(-2:2)
cv.svm.results <- tune.svm(train.exp.mat,train.labels,gamma = gamma, cost = cost ,probability = TRUE)
cv.svm.results$best.parameters
# Perform prediction using best model
pred.proba <- predict(cv.svm.results$best.model,newdata=test.exp.mat,probability = TRUE)

# Evaluate performance
roc.curve <- roc(test.labels,as.numeric(pred.proba))
ci.auc(roc.curve,x="best",conf.level = 0.95)
plot(1-roc.curve$specificities,roc.curve$sensitivities,type="l")
ci.coords(roc.curve,x="best",conf.level = 0.95,ret = c("recall","precision"))
```

## Random Forest
- Use package `randomForest`
```{R}
library(randomForest)
rf.model.fitted <- randomForest(train.exp.mat,train.labels)
pred.proba <- predict(rf.model.fitted,newdata=test.exp.mat,type="prob")
pred.proba <- pred.proba[,"tumor"]
roc.curve <- roc(test.labels,as.numeric(pred.proba))
ci.auc(roc.curve,x="best",conf.level = 0.95)
plot(1-roc.curve$specificities,roc.curve$sensitivities,type="l")
ci.coords(roc.curve,x="best",conf.level = 0.95,ret = c("recall","precision"))
```

